{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antony/Documents/Visual Studio Code/clip/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import CLIPModel, CLIPProcessor, CLIPConfig, CLIPTextConfig, CLIPVisionConfig\n",
    "from transformers import pipeline\n",
    "from PIL import Image\n",
    "from typing import Type\n",
    "import transformers\n",
    "import requests\n",
    "import torch\n",
    "import copy\n",
    "import sys\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPModel, CLIPSegModel, CLIPTextModel, CLIPTextModelWithProjection, CLIPVisionModelWithProjection, CLIPVisionModel\n",
    "from transformers import CLIPSegTextModel, CLIPSegVisionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, AutoTokenizer, AutoBackbone, AutoProcessor, AutoModel, AutoFeatureExtractor, CLIPVisionConfig, CLIPTokenizer, CLIPTokenizerFast\n",
    "from transformers import PreTrainedTokenizerFast, PreTrainedTokenizer, CLIPImageProcessor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c2 = CLIPSegModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c3 = CLIPTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c4 = CLIPTextModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c5 = CLIPVisionModelWithProjection.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c6 = CLIPVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c7 = CLIPSegTextModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "c8 = CLIPSegVisionModel.from_pretrained(\"openai/clip-vit-base-patch32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equals = []\n",
    "for x, y in zip(c.vision_model.parameters(), c6.parameters()):\n",
    "    equals.append(x.equal(y))\n",
    "all(equals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "tok:CLIPTokenizerFast = CLIPTokenizerFast.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "vis = CLIPImageProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n",
    "image = Image.open(requests.get(url, stream=True).raw)\n",
    "img = Image.open(\"./save.png\")\n",
    "text = [\"a photo of a cat\", \"a photo of a dog\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_inputs = processor(text=text, images=image, return_tensors=\"pt\", padding=True)\n",
    "outputs = clip(**pad_inputs)\n",
    "logits_per_image = outputs.logits_per_image  # this is the image-text similarity score\n",
    "probs = logits_per_image.softmax(dim=1) # we can take the softmax to get the label probabilities\n",
    "\n",
    "tex_tok = tok(text=text, return_tensors=\"pt\")\n",
    "vis_img = vis(img, return_tensors=\"pt\")\n",
    "inputs = processor(text=text, images=img, return_tensors=\"pt\")\n",
    "\n",
    "outputs2 = clip(**tex_tok, **vis_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CLIPProcessor' object has no attribute 'eos_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprocessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meos_token\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CLIPProcessor' object has no attribute 'eos_token'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[49406,   320,  1125,   539,   320,  2368, 49407],\n",
       "        [49406,   320,  1125,   539,   320,  1929, 49407]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPModel(\n",
       "  (text_model): CLIPTextTransformer(\n",
       "    (embeddings): CLIPTextEmbeddings(\n",
       "      (token_embedding): Embedding(49408, 512)\n",
       "      (position_embedding): Embedding(77, 512)\n",
       "    )\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (vision_model): CLIPVisionTransformer(\n",
       "    (embeddings): CLIPVisionEmbeddings(\n",
       "      (patch_embedding): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "      (position_embedding): Embedding(50, 768)\n",
       "    )\n",
       "    (pre_layrnorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (encoder): CLIPEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x CLIPEncoderLayer(\n",
       "          (self_attn): CLIPAttention(\n",
       "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): CLIPMLP(\n",
       "            (activation_fn): QuickGELUActivation()\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (post_layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (visual_projection): Linear(in_features=768, out_features=512, bias=False)\n",
       "  (text_projection): Linear(in_features=512, out_features=512, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[49406,   320,  1125,   539,   320,  2368, 49407],\n",
      "        [49406,   320,  1125,   539,   320,  1929, 49407]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]]), 'pixel_values': tensor([[[[ 0.5873,  0.5873,  0.6165,  ...,  0.0617,  0.0471, -0.0259],\n",
      "          [ 0.5727,  0.5727,  0.6603,  ...,  0.1201,  0.0763,  0.0909],\n",
      "          [ 0.5873,  0.5435,  0.6165,  ...,  0.0325,  0.1201,  0.0617],\n",
      "          ...,\n",
      "          [ 1.8719,  1.8573,  1.8719,  ...,  1.3902,  1.4340,  1.4194],\n",
      "          [ 1.8281,  1.8719,  1.8427,  ...,  1.4486,  1.4340,  1.5070],\n",
      "          [ 1.8573,  1.9011,  1.8281,  ...,  1.3756,  1.3610,  1.4486]],\n",
      "\n",
      "         [[-1.3169, -1.3019, -1.3169,  ..., -1.4970, -1.4369, -1.4820],\n",
      "          [-1.2418, -1.2718, -1.2268,  ..., -1.4369, -1.4669, -1.4519],\n",
      "          [-1.2568, -1.3169, -1.2268,  ..., -1.4669, -1.4069, -1.4519],\n",
      "          ...,\n",
      "          [ 0.1239,  0.1089,  0.1239,  ..., -0.7016, -0.6865, -0.6865],\n",
      "          [ 0.0789,  0.0939,  0.0488,  ..., -0.6565, -0.6865, -0.6115],\n",
      "          [ 0.0939,  0.1089,  0.0038,  ..., -0.7766, -0.7316, -0.6115]],\n",
      "\n",
      "         [[-0.4848, -0.4137, -0.3853,  ..., -0.9541, -0.8545, -0.8545],\n",
      "          [-0.4137, -0.4706, -0.3711,  ..., -0.8119, -0.8545, -0.7834],\n",
      "          [-0.3284, -0.4422, -0.3853,  ..., -0.8688, -0.8119, -0.8830],\n",
      "          ...,\n",
      "          [ 1.5771,  1.6482,  1.6340,  ...,  0.9088,  0.9514,  0.8945],\n",
      "          [ 1.6198,  1.6055,  1.6055,  ...,  0.8661,  0.8092,  0.7950],\n",
      "          [ 1.6624,  1.6766,  1.5487,  ...,  0.7950,  0.8661,  0.8519]]]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'pixel_values'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(pad_inputs)\n",
    "pad_inputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(inputs['input_ids'].shape)\n",
    "print(inputs['attention_mask'].shape)\n",
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_img['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tex_tok['input_ids'].shape)\n",
    "tex_tok['attention_mask'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIPOutput(loss=None, logits_per_image=tensor([[18.8830, 20.3125]], grad_fn=<TBackward0>), logits_per_text=tensor([[18.8830],\n",
       "        [20.3125]], grad_fn=<MulBackward0>), text_embeds=tensor([[ 0.0148,  0.0070, -0.0234,  ..., -0.0508, -0.0438,  0.0033],\n",
       "        [ 0.0087,  0.0258, -0.0387,  ..., -0.0547, -0.0242,  0.0112]],\n",
       "       grad_fn=<DivBackward0>), image_embeds=tensor([[-4.2393e-02,  2.0662e-03, -4.9599e-04,  1.3198e-02, -9.5169e-03,\n",
       "         -7.6227e-03,  6.7158e-03,  3.4872e-02,  1.5002e-02, -1.5889e-02,\n",
       "          2.9736e-02,  3.9923e-03,  4.1415e-02,  1.3504e-02, -7.1151e-03,\n",
       "         -2.6903e-03,  1.2073e-01, -1.4583e-02, -1.7149e-03,  2.4115e-02,\n",
       "          1.0852e-01,  1.7230e-02,  1.7736e-03, -6.0261e-02,  6.5560e-03,\n",
       "          3.9052e-02,  8.8093e-03, -1.2709e-02,  1.9773e-02, -2.2983e-02,\n",
       "         -2.0093e-02,  2.9158e-02, -5.6362e-03,  9.1024e-03,  8.7693e-02,\n",
       "          3.3201e-03,  1.3148e-02,  1.6944e-02, -1.5307e-02, -8.3911e-02,\n",
       "          9.2842e-03, -7.8838e-03,  3.2277e-03, -5.0966e-02,  1.5286e-02,\n",
       "          1.1459e-02,  8.8401e-03,  9.3336e-03, -1.4112e-02,  2.5505e-02,\n",
       "         -2.3728e-02, -2.7752e-02,  5.2602e-03, -4.5987e-02, -4.7321e-03,\n",
       "          4.7209e-02,  1.3059e-02,  1.1943e-02, -1.4407e-02,  8.8461e-04,\n",
       "         -1.5051e-03,  2.5368e-02,  2.5218e-02,  5.2141e-02, -2.1485e-02,\n",
       "         -2.2021e-03,  2.9142e-02,  1.0968e-01,  8.8082e-03,  1.6563e-02,\n",
       "         -2.4430e-02, -2.0546e-03, -3.9526e-02,  3.1760e-02, -1.4865e-02,\n",
       "         -3.7899e-04,  1.1364e-02, -3.0936e-03, -1.8658e-03, -2.8667e-03,\n",
       "          4.4155e-02, -2.8038e-02, -4.4157e-02, -2.8450e-02,  2.8129e-02,\n",
       "          3.4071e-02,  1.4338e-01,  5.2330e-02,  9.4158e-03, -2.2275e-02,\n",
       "          4.2372e-02, -2.6358e-03, -6.5910e-01, -5.4028e-02,  1.3003e-02,\n",
       "         -3.8987e-02, -8.9756e-03, -2.4005e-02,  1.6817e-02,  6.9350e-02,\n",
       "          2.9512e-02,  3.1638e-02,  2.3360e-02, -5.4352e-02, -4.8828e-02,\n",
       "          3.6362e-02, -1.3939e-01,  1.7840e-03,  3.9050e-03, -7.9180e-03,\n",
       "          1.0133e-02, -1.1293e-01, -5.8056e-03, -4.6600e-03, -4.3293e-02,\n",
       "          1.3654e-02, -1.1611e-02, -1.0429e-02,  4.0414e-02, -1.6242e-02,\n",
       "          8.1756e-03,  5.3181e-02, -1.5881e-02, -2.4577e-02, -6.5669e-03,\n",
       "         -2.6002e-02, -6.8899e-03,  1.9656e-02,  7.6636e-03,  3.7064e-02,\n",
       "          3.0247e-02,  3.9718e-02,  1.8071e-02,  9.0464e-02, -2.3040e-02,\n",
       "          3.1780e-02,  1.5520e-02, -7.1075e-02, -5.5558e-03, -2.0454e-02,\n",
       "         -3.9792e-02,  7.6876e-04,  6.7589e-02,  2.0901e-02, -1.0847e-02,\n",
       "          5.2045e-03, -1.4504e-02,  1.0839e-03,  6.5474e-03,  4.8593e-02,\n",
       "         -2.0969e-03,  1.2497e-02, -2.0525e-02,  5.0033e-02, -1.0008e-02,\n",
       "         -5.3771e-02, -9.6715e-02,  2.4483e-02,  1.7273e-02, -2.5381e-02,\n",
       "         -4.4084e-02, -5.5878e-03, -1.6934e-02, -1.1498e-02,  4.4933e-02,\n",
       "          4.5241e-03,  1.0167e-01,  6.6312e-02,  1.5138e-02,  9.9249e-03,\n",
       "          1.9733e-02, -4.5710e-03, -6.9274e-03, -3.8874e-03, -9.5503e-03,\n",
       "          3.1394e-02,  2.2825e-02,  2.8922e-02, -3.3379e-02,  3.6912e-02,\n",
       "          2.5983e-02, -4.4543e-02,  1.8768e-02,  2.7283e-02, -4.2479e-02,\n",
       "         -1.4927e-02,  6.6635e-03,  2.8811e-02, -4.3632e-03, -3.3354e-02,\n",
       "         -2.4912e-02,  2.5848e-02, -1.3000e-03,  2.2909e-02,  2.9015e-02,\n",
       "         -1.6760e-02, -9.9961e-03, -2.8908e-02, -2.5930e-02,  2.2396e-02,\n",
       "          2.5241e-02,  6.6972e-03, -2.0852e-03,  1.2702e-02,  1.7489e-02,\n",
       "          2.3831e-03, -1.5154e-02,  1.6686e-02,  4.8389e-02,  1.9163e-02,\n",
       "         -2.7137e-02,  6.9719e-02, -7.2364e-03,  3.4557e-03, -1.5791e-02,\n",
       "         -4.5210e-02,  3.1642e-02,  2.7324e-02,  1.2387e-01,  1.3888e-03,\n",
       "         -2.8951e-02,  6.2316e-02, -3.9619e-03,  4.0334e-02,  9.6090e-03,\n",
       "         -2.5296e-02,  3.1763e-02, -4.2621e-02,  6.9963e-03,  2.3791e-02,\n",
       "          2.2043e-02,  8.7571e-03, -2.1308e-02,  7.1131e-03,  2.7978e-02,\n",
       "          4.5284e-02,  1.1464e-02, -2.6881e-03, -3.3051e-03, -4.2073e-02,\n",
       "          5.4495e-02,  4.1247e-02,  4.2713e-02, -1.3332e-02, -3.3006e-02,\n",
       "          1.3668e-02, -1.2584e-02,  2.7753e-02,  2.5495e-02, -2.2368e-02,\n",
       "         -6.0561e-02,  2.6730e-02,  3.0843e-02,  2.2341e-04, -3.5060e-02,\n",
       "          1.0294e-02, -2.4473e-02, -1.4169e-02, -8.7088e-02,  3.3677e-02,\n",
       "          2.1231e-02,  6.2896e-03, -9.4722e-03, -7.2260e-02,  3.6105e-02,\n",
       "         -3.2872e-02, -2.2642e-02,  2.5763e-02, -1.6472e-02, -4.7353e-02,\n",
       "          2.8525e-02,  4.6796e-02, -1.3198e-03,  2.7788e-02,  2.2105e-02,\n",
       "         -2.1934e-02, -3.2336e-02,  9.0420e-04, -3.3415e-03, -9.2174e-03,\n",
       "          2.5961e-03, -3.4618e-02, -1.9538e-02, -2.5933e-02, -2.0059e-03,\n",
       "         -1.3963e-02,  5.3238e-02,  1.0407e-02,  1.4966e-02, -1.9569e-02,\n",
       "         -1.1166e-02, -1.4627e-02,  2.0704e-02, -1.6159e-02, -4.2385e-04,\n",
       "         -1.8406e-03, -1.5698e-02,  2.6776e-02,  2.9424e-04,  2.1355e-02,\n",
       "          4.0468e-03, -4.2265e-02,  1.4211e-02, -2.6087e-02, -1.3091e-03,\n",
       "         -3.5741e-02, -2.5535e-02, -4.2137e-03,  7.0560e-02, -1.3737e-02,\n",
       "         -5.3812e-02,  3.5356e-02,  9.0346e-02, -2.4193e-02,  3.7474e-02,\n",
       "          5.2802e-02, -2.3287e-02, -2.6247e-02, -1.7744e-03, -2.6407e-02,\n",
       "         -2.4673e-02, -7.0968e-02, -1.2470e-02, -8.3005e-03, -3.4753e-02,\n",
       "          7.6547e-03, -3.4519e-02,  1.2630e-02, -7.2424e-03, -1.0470e-03,\n",
       "         -5.7583e-03, -3.0869e-02,  3.8644e-02, -1.2797e-02, -3.4801e-02,\n",
       "          1.9235e-02,  1.8767e-03,  7.9441e-03, -2.1386e-03, -1.3317e-02,\n",
       "          4.1960e-02,  3.6659e-03, -8.0252e-03, -3.4022e-02, -2.5755e-02,\n",
       "         -3.3396e-02,  5.3149e-02, -1.6333e-02,  3.0839e-03,  3.2987e-02,\n",
       "          6.7306e-02, -9.3212e-03,  5.2575e-02, -1.6620e-02,  3.3141e-02,\n",
       "          4.4438e-02, -1.5437e-02,  7.9183e-02,  1.8562e-02, -3.0531e-02,\n",
       "         -3.6913e-02,  1.7660e-02, -1.5791e-02,  3.5913e-02,  6.9886e-02,\n",
       "          9.3633e-03, -5.0819e-02, -1.5616e-02, -9.1162e-03, -2.3143e-02,\n",
       "         -7.1267e-03,  1.3750e-02,  3.3873e-02, -2.2822e-02,  6.1171e-02,\n",
       "          2.4614e-02,  5.9269e-02,  2.8996e-02, -4.3469e-03, -3.0490e-03,\n",
       "          4.3053e-03, -1.1222e-02,  3.2610e-02,  2.9242e-03, -2.9032e-03,\n",
       "          3.3003e-02,  1.3713e-02, -4.0530e-04, -1.5578e-02, -7.3264e-03,\n",
       "         -4.4100e-02,  3.3966e-02,  1.1052e-02,  1.9346e-02,  2.0988e-04,\n",
       "         -1.0111e-02,  5.0787e-03, -3.4122e-02, -4.3890e-02, -5.2637e-02,\n",
       "          1.9809e-02, -9.3892e-03,  5.5940e-02, -2.4265e-02,  1.1203e-02,\n",
       "          2.2661e-02, -4.7454e-03, -3.4008e-02, -3.6790e-02,  5.2367e-03,\n",
       "         -1.5993e-02,  9.3324e-03,  1.3780e-02,  1.7177e-02, -1.7756e-03,\n",
       "          3.0372e-03,  3.3648e-02,  4.6255e-03, -6.7801e-03,  2.4833e-02,\n",
       "         -1.4898e-02, -6.7230e-02, -1.5664e-02, -8.1584e-02, -1.7961e-02,\n",
       "         -2.6583e-04,  3.2618e-03,  2.3624e-02, -8.3165e-02,  7.7673e-03,\n",
       "         -2.8939e-02,  2.0447e-02, -2.6560e-02,  8.4263e-03, -3.8829e-02,\n",
       "          1.1323e-02,  1.1918e-03, -3.2525e-02,  1.5439e-02, -1.3190e-02,\n",
       "         -1.4388e-02,  6.4784e-02, -5.4238e-02,  1.1141e-02,  5.8679e-03,\n",
       "          4.8385e-02,  2.2490e-02, -1.5873e-02, -3.3423e-02,  3.0690e-03,\n",
       "         -9.9138e-03, -2.7819e-02,  7.1174e-04, -2.2063e-02,  1.5525e-02,\n",
       "         -3.8298e-03,  2.3264e-02, -9.2144e-03, -1.5180e-02,  2.4223e-02,\n",
       "         -3.9943e-02, -2.3181e-02, -2.2619e-02, -4.5782e-02,  4.4223e-02,\n",
       "         -4.8846e-03, -2.5352e-02,  2.1461e-03, -1.3768e-02, -7.1834e-03,\n",
       "          2.4138e-02,  4.6417e-04,  2.4382e-03, -6.9015e-02,  1.0022e-02,\n",
       "         -3.1702e-02, -1.9143e-02, -1.2050e-02, -5.4096e-03, -3.0017e-03,\n",
       "         -7.4076e-04, -4.1849e-02, -2.2491e-02,  4.4211e-02, -3.1318e-02,\n",
       "         -1.6469e-02, -2.3976e-03, -5.4994e-03, -5.3135e-03, -5.3152e-02,\n",
       "          1.9976e-02, -8.6791e-03,  2.2182e-02, -8.5273e-02,  6.3661e-03,\n",
       "          2.7000e-02,  2.9595e-02, -1.6068e-02, -3.2202e-02,  3.3172e-02,\n",
       "         -5.6925e-03, -5.4472e-03, -4.0877e-03,  1.3799e-02,  7.5539e-02,\n",
       "         -2.3069e-02, -6.1477e-03, -2.1695e-02, -2.1561e-02,  6.5501e-02,\n",
       "         -7.7367e-03,  4.3804e-03]], grad_fn=<DivBackward0>), text_model_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
       "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
       "         [ 1.0580, -0.9600,  1.0018,  ..., -0.5155, -0.1437, -1.9444],\n",
       "         ...,\n",
       "         [ 0.3059, -1.5037, -0.4022,  ..., -0.0224,  0.9105, -0.3916],\n",
       "         [ 1.0118, -0.6701,  1.7742,  ..., -0.1556, -0.0250, -1.5062],\n",
       "         [-0.5152,  0.1658,  0.8876,  ..., -0.0675, -0.4551, -1.7960]],\n",
       "\n",
       "        [[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
       "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
       "         [ 1.0580, -0.9600,  1.0018,  ..., -0.5155, -0.1437, -1.9444],\n",
       "         ...,\n",
       "         [ 0.3059, -1.5037, -0.4022,  ..., -0.0224,  0.9105, -0.3916],\n",
       "         [-0.1433, -0.5163,  1.7099,  ..., -0.0795,  0.3609, -1.2437],\n",
       "         [ 0.0426,  0.0189,  1.2740,  ..., -0.4217, -0.4393, -1.3016]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.5152,  0.1658,  0.8876,  ..., -0.0675, -0.4551, -1.7960],\n",
       "        [ 0.0426,  0.0189,  1.2740,  ..., -0.4217, -0.4393, -1.3016]],\n",
       "       grad_fn=<IndexBackward0>), hidden_states=None, attentions=None), vision_model_output=BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 6.1829e-02,  4.7678e-01, -1.8373e-01,  ...,  5.4813e-02,\n",
       "           3.1411e-01, -3.8166e-04],\n",
       "         [-2.0827e-02,  8.0115e-02, -4.6851e-01,  ...,  4.8316e-02,\n",
       "           2.0728e-01,  3.5347e-01],\n",
       "         [ 1.0167e-01,  2.2119e-01, -1.8040e-01,  ..., -1.9964e-02,\n",
       "           1.0472e-01,  3.5965e-01],\n",
       "         ...,\n",
       "         [ 9.3780e-01,  4.4054e-02,  8.1232e-01,  ...,  1.0455e+00,\n",
       "           9.7427e-01, -2.8704e-01],\n",
       "         [ 9.1434e-01,  2.7914e-01,  1.5963e-02,  ...,  3.2047e-01,\n",
       "           7.8019e-01, -3.5206e-01],\n",
       "         [ 2.8618e-03,  6.9275e-01, -2.6724e-01,  ..., -9.3575e-02,\n",
       "           3.0899e-01,  2.7504e-01]]], grad_fn=<AddBackward0>), pooler_output=tensor([[ 4.3434e-01,  1.5170e+00, -5.3869e-01,  6.2862e-01, -2.6969e-02,\n",
       "         -1.5659e+00,  5.7648e-01,  5.1445e-01, -1.4210e-01,  8.8578e-01,\n",
       "         -6.5233e-01,  8.1321e-01, -4.1474e-01,  8.8783e-01,  9.8924e-03,\n",
       "          1.6029e+00, -1.9187e+00,  4.2005e-01, -6.5771e-01,  3.2167e-02,\n",
       "         -1.1681e-01,  6.5591e-01,  5.7559e-01,  1.1834e-01, -1.0930e+00,\n",
       "          1.2687e-01,  4.6033e-01, -9.7433e-01, -6.4252e-01,  7.6587e-01,\n",
       "         -5.7425e+00, -1.7194e+00,  4.8721e-01, -2.0468e+00,  7.6696e-01,\n",
       "          1.1166e+00,  1.8747e+00, -1.8078e-01,  1.3918e+00, -4.7459e-01,\n",
       "          7.3791e-01, -6.4007e-01, -4.8853e-01,  8.1776e-01, -1.1381e+00,\n",
       "          3.5224e-01,  1.0421e-01,  6.3709e-01,  5.3434e-01,  6.4758e-01,\n",
       "          3.3057e-01, -9.8330e-01,  6.0270e-01,  1.0318e+00, -1.2052e+00,\n",
       "          1.1548e+00,  5.3402e-02,  1.9850e+00, -5.0637e-01,  1.5622e+00,\n",
       "         -1.9163e-03,  1.4493e+00,  9.0655e-02, -4.0827e-01, -2.5067e-01,\n",
       "          8.5763e-02, -1.1087e-01,  8.0450e-01, -7.6376e-01, -1.9867e-01,\n",
       "         -1.6915e-01, -7.6219e-01, -7.7751e-01, -1.7799e+00,  2.1431e+00,\n",
       "         -3.2279e-01,  5.3366e-01, -1.7317e+00,  4.9525e-01,  2.0630e-01,\n",
       "          1.6398e-01, -2.1858e+00,  3.9204e-01, -9.1072e-01,  1.2953e+00,\n",
       "         -4.0115e-01,  3.8611e-01, -8.0892e-02, -6.5001e-02,  1.3056e-01,\n",
       "          1.0266e+00,  4.1482e-01,  1.0408e+00,  3.9610e-01, -7.8134e-01,\n",
       "          3.3589e-01, -2.6096e-02,  3.4004e-01, -1.9985e-01, -1.5581e+00,\n",
       "         -8.7519e-01, -7.0097e-01, -1.4349e-01, -2.4972e-01, -1.5709e+00,\n",
       "          1.5829e+00,  2.4291e-01,  8.5316e-01,  1.2922e+00, -5.3872e-01,\n",
       "         -5.3988e-01,  7.6599e-01,  7.4446e-01, -7.5317e-01, -1.2021e+00,\n",
       "         -8.6393e-01,  8.6230e-01, -3.8837e+00,  1.2508e+00,  1.4459e+00,\n",
       "         -8.6912e-02,  6.8055e-02,  1.6831e+00, -3.0656e-01, -1.9438e+00,\n",
       "          2.7970e-01, -1.2307e-01,  1.1828e+00, -1.5109e+00,  1.1145e+00,\n",
       "         -4.4067e-01,  2.7492e-01,  1.2727e+00,  8.1332e-01,  1.7920e-01,\n",
       "          1.9010e+00, -1.0855e+00,  3.3162e-01,  5.1137e-01,  1.7254e-01,\n",
       "          2.7508e-01,  1.0120e+00, -2.5047e-01, -2.5058e-02, -8.0553e-02,\n",
       "         -6.1196e-01, -2.5892e-01, -9.1971e-01, -3.1386e-01, -8.8901e-01,\n",
       "          1.4155e-01,  4.2247e-02, -2.1750e-01,  7.3617e-01,  6.7617e-02,\n",
       "          4.6259e-02,  1.4504e+00,  2.7869e-02,  4.1157e-01, -3.0182e-01,\n",
       "          9.6198e-01,  1.4022e+00, -4.8248e-01, -2.1291e-01,  4.7233e-01,\n",
       "          1.6432e+00, -6.3556e-01,  2.8357e+00, -3.3143e-01,  1.3315e-01,\n",
       "          1.5218e+00, -7.2719e-01, -5.4139e-02, -3.5860e+00, -5.6543e-01,\n",
       "          2.2574e-01,  3.8813e-01,  4.4194e-01, -6.7419e-01,  7.2508e-01,\n",
       "          9.8688e-02, -2.0563e-01,  2.0859e-01, -1.0240e-01,  5.6289e-01,\n",
       "          1.5649e+00, -1.0054e+00,  2.5621e-01,  1.8666e+00,  1.9696e+00,\n",
       "          1.0731e+00, -2.6945e-01,  1.3479e+00,  1.1419e-01,  4.8271e-01,\n",
       "          6.0703e-01,  1.1030e+00, -4.0502e-01,  5.5384e-01,  1.4650e+00,\n",
       "          1.3888e+00,  5.7748e-01,  1.4723e+00, -1.5569e-01,  1.1904e+00,\n",
       "          2.7640e-01,  2.2198e-01,  7.4719e-02, -1.6814e-01, -4.1087e-01,\n",
       "         -9.1976e-01,  3.1873e-01,  2.9954e-01,  1.4472e-01,  1.1024e-01,\n",
       "          6.7367e-01,  4.5554e-02,  8.6307e-01, -6.3934e-02,  1.2510e+00,\n",
       "         -5.3302e-01, -1.4366e+00,  1.2644e+00,  8.1940e-01, -5.5431e-01,\n",
       "          5.6588e-01,  3.7043e-01, -3.9329e-01,  1.3719e+00, -3.1110e-01,\n",
       "         -5.4814e-01,  9.1402e-01,  9.5914e-01,  3.2314e-01, -5.0032e-01,\n",
       "          9.3759e-01,  1.7119e+00, -4.7716e-01,  8.8916e-01, -5.4766e-01,\n",
       "         -5.7004e-01,  5.5970e-01,  1.1068e+00,  1.4673e-03, -4.1228e-01,\n",
       "         -2.8370e-01,  5.6613e-01, -4.6048e-01, -5.5284e-02,  1.0698e+00,\n",
       "         -9.2231e-02, -2.8958e-01, -1.2324e+00, -9.1393e-01,  3.5964e-01,\n",
       "          1.2005e-01, -6.6773e-01, -1.3701e+00,  4.8159e-01,  5.3561e-01,\n",
       "         -5.1353e-01,  1.2594e+00,  8.9251e-01,  1.9562e-01,  8.7754e-01,\n",
       "          5.4991e-01, -4.2329e-01,  1.0065e+00,  7.1518e-01, -1.5178e-01,\n",
       "          2.3364e-01,  1.1512e+00, -1.0362e+00, -3.1913e-01,  2.5882e-01,\n",
       "         -2.4690e-01, -7.6216e-01, -7.3117e-03,  1.3814e-01,  1.6517e+00,\n",
       "          2.2003e-01,  3.7952e-01,  2.8235e-02,  1.8194e+00,  1.0905e-01,\n",
       "          1.0771e+00,  3.5963e-01,  5.7898e-02,  7.4896e-01, -1.3560e+00,\n",
       "         -9.0849e-01,  6.3154e-01, -8.2274e-01,  9.5758e-02, -1.2030e+00,\n",
       "          7.1495e-01,  8.2842e-02, -1.2544e+00, -6.7803e-01,  8.3620e-01,\n",
       "         -7.4550e-01, -1.4089e+00,  7.9010e-01, -7.0836e-01, -2.3642e-01,\n",
       "         -7.6406e-01, -1.1089e-01,  3.4646e-01,  2.6596e+00, -2.0026e-01,\n",
       "          3.8545e-02,  1.6940e+00,  4.3063e-02,  1.2703e+00, -4.5364e-01,\n",
       "          1.1437e+00,  7.1413e-01,  7.7172e-01,  8.8498e-01, -5.7625e-01,\n",
       "          2.5296e-01,  1.3630e-01, -2.0385e-01,  1.4951e+00,  1.4434e-01,\n",
       "          5.7228e-01,  1.0751e+00,  1.0578e+00,  8.1652e-01,  8.8496e-01,\n",
       "         -6.6904e-01,  1.3534e+00,  7.6570e-01, -3.0576e-02, -3.3881e-01,\n",
       "          6.7279e-01, -3.2960e+00, -2.4999e-01,  6.6185e-01, -2.1078e-01,\n",
       "         -2.0041e-01, -9.6206e-01,  3.5118e-01,  1.3041e+00, -5.8412e-01,\n",
       "         -7.4506e-01,  3.7895e-01, -5.5260e-01, -1.2982e-01,  6.0699e-01,\n",
       "          3.4550e-01, -2.7411e-01, -3.4281e-01,  5.7842e-03, -6.4537e-01,\n",
       "          1.3143e+00,  7.9412e-01, -3.8600e-01, -7.4443e-03,  2.1947e-01,\n",
       "          6.3079e-02, -7.9468e-01, -4.4090e-01,  6.8564e-01,  3.9890e-01,\n",
       "          4.6495e-01,  2.3532e-02, -4.7898e-01, -1.8609e-01,  1.4185e-01,\n",
       "          6.4099e-01,  3.1076e-01,  1.2512e+00,  4.1685e-01, -7.2024e-01,\n",
       "         -1.3949e-01, -4.5224e-01, -1.2442e+00,  5.6829e-01, -2.4380e-01,\n",
       "          9.8288e-01, -3.3921e-01, -1.3283e+00,  1.2387e+00,  8.5428e-01,\n",
       "          7.3659e-02, -1.8980e-02, -1.9997e-01,  1.4442e-01,  6.3817e-01,\n",
       "          3.4892e-01,  1.4701e+00, -1.1887e+00,  6.1022e-01, -3.4826e-01,\n",
       "          2.1228e+00, -4.2642e-01,  4.4351e-01,  1.3431e-01,  1.1154e+00,\n",
       "         -4.1334e-01, -3.3044e-01, -1.0450e+00,  3.9626e-02, -4.9323e-02,\n",
       "          8.1022e-01,  1.2013e+00,  1.2262e+00,  9.5281e-01,  1.3612e+00,\n",
       "          1.2410e+00,  1.1997e+00, -1.0060e-01,  2.5809e-02, -3.1576e-01,\n",
       "          1.4305e+00, -3.3658e-01,  1.9365e+00, -2.1051e+00,  8.3747e-02,\n",
       "          5.5676e-01,  2.2081e-01,  1.7478e+00, -7.6810e-01,  1.3778e+00,\n",
       "          4.9018e-02, -6.8481e-01,  4.8056e-01,  8.7630e-01,  4.4685e-01,\n",
       "          6.2466e-01,  2.4282e-01, -7.6928e-01,  5.6088e-01,  1.8444e-01,\n",
       "         -2.2948e-01,  1.7016e+00, -1.9061e-01,  5.7471e-01,  7.3568e-01,\n",
       "         -1.1279e-01, -2.3037e-01, -2.4462e-01,  6.2429e-01, -1.1861e+00,\n",
       "          5.7946e-01,  4.1839e-01, -5.2664e-01,  1.6097e+00, -1.6371e-01,\n",
       "          1.1546e+00, -2.8694e-02,  9.8080e-01,  1.8209e-01, -6.4894e-01,\n",
       "         -5.0431e-01, -5.8660e-01, -1.4117e-02,  2.8729e-01, -9.5449e-01,\n",
       "          1.8807e+00, -1.3566e+00, -4.5829e-01,  2.2635e-01,  1.5471e+00,\n",
       "         -9.3703e-01, -1.2145e-01,  1.4904e+00, -9.8572e-01, -2.6061e-01,\n",
       "          6.9028e-01,  1.3567e+00,  1.4321e+00,  8.0940e-01,  3.3795e-04,\n",
       "         -1.4569e-01, -3.5765e-01, -4.7636e-01, -4.9905e-01, -4.3849e-01,\n",
       "          4.9297e-01,  2.2405e-01,  2.1794e-01,  2.0675e+00,  5.5250e+00,\n",
       "          5.2173e-01, -3.6857e-01,  8.4312e-01,  6.6313e-01,  4.6869e-01,\n",
       "         -1.0256e+00,  3.9150e-01,  6.5645e-01, -1.1040e+00,  2.0943e+00,\n",
       "          1.3552e+00,  2.7105e-01, -4.0762e-01,  1.5690e-01,  1.2201e+00,\n",
       "          4.0703e-02, -1.0387e+00,  1.8655e+00, -7.5127e-02, -3.3962e-01,\n",
       "          8.9004e-01,  2.9874e-01, -4.9584e-01,  1.4360e+00,  5.1071e-02,\n",
       "         -1.0167e-01,  1.7103e-01, -1.0789e+00,  2.3122e-01,  9.2560e-01,\n",
       "          9.2761e-02, -2.1725e-01, -5.7033e-01,  5.1061e-02, -3.5104e-01,\n",
       "         -3.0759e+00, -3.2673e-01,  4.5020e-01,  2.7421e-01, -4.6282e-01,\n",
       "         -2.3858e-01,  1.4423e-01,  1.5953e+00, -4.8570e-01, -2.0452e-01,\n",
       "          6.4560e-01, -4.1050e-01, -3.4728e-01,  9.7424e-01, -4.7498e-01,\n",
       "         -3.0213e-01,  9.6280e-01, -3.3158e-01,  1.0289e+00, -4.9933e-01,\n",
       "          3.2034e-01, -6.2499e-01,  5.6987e-01, -1.7206e+00,  1.8988e-01,\n",
       "          3.5565e-01,  1.7228e+00,  7.5180e-02, -4.1366e-01, -7.3280e-01,\n",
       "         -4.6951e-02,  4.8386e-01, -5.4880e-01,  8.9016e-01, -4.3189e-01,\n",
       "         -1.8733e-01,  3.2809e-01, -2.3587e-01, -5.0285e-01,  5.4188e-01,\n",
       "          5.5873e-01, -6.0711e-01,  1.1414e+00,  8.9839e-01,  1.4378e+00,\n",
       "         -4.0889e-01, -6.5543e-01,  1.4336e+00,  1.5292e-02, -2.7579e-02,\n",
       "          1.3027e+00, -3.9902e-01, -8.7985e-01, -8.8633e-01,  7.5478e-01,\n",
       "         -4.6252e-02, -1.0889e+00,  2.2762e+00,  2.1231e-01,  1.5220e+00,\n",
       "         -3.9539e-01,  1.4345e+00,  4.4353e-01, -4.4836e-01, -5.1848e-01,\n",
       "          4.4550e-01,  3.9199e-01, -2.0309e+00,  5.5777e-01,  1.8685e-01,\n",
       "          1.0418e+00, -3.7329e-01,  1.1700e+00, -1.7647e-01, -8.6365e-01,\n",
       "          1.1191e-01,  2.4465e-02, -8.7406e-01, -6.1064e-02,  5.6651e-01,\n",
       "         -1.0960e+00,  1.1138e+00,  3.1035e-01,  1.6338e+00,  1.0732e+00,\n",
       "         -7.0322e-01,  6.5747e-01,  5.9044e-01,  1.3680e-01, -4.0038e-01,\n",
       "          1.6139e-02,  1.1003e+00,  1.4160e+00, -1.0700e+00, -5.3716e-01,\n",
       "          1.8805e-01,  1.4315e+00, -5.3553e-01,  1.7504e+00, -7.5184e-01,\n",
       "          2.7993e-01,  3.0476e-01,  3.9154e-01, -3.2019e-01,  6.4525e+00,\n",
       "          2.9182e+00,  5.2032e-01,  3.7926e-01,  3.0025e-01,  1.8429e+00,\n",
       "          1.5673e+00,  8.9619e-01,  1.8289e-01, -8.5795e-01,  1.4087e+00,\n",
       "          7.4416e-01,  1.5951e+00,  2.6269e-01,  1.2939e+00, -4.2774e-01,\n",
       "          1.3227e-01, -6.8665e-01,  2.0182e+00, -7.8670e-02,  6.4760e-01,\n",
       "          8.3186e-01,  4.1386e-01, -9.7661e-02, -1.2144e+00, -1.8277e-01,\n",
       "         -1.0925e+00, -5.1830e-01,  3.5578e-01,  6.7732e-01,  6.3733e-01,\n",
       "         -5.7748e-01, -2.5994e-01, -5.4124e-02,  1.0907e-01,  7.0154e-01,\n",
       "         -2.9434e-03, -4.5036e-01,  5.4583e-01,  2.4953e-01,  9.3975e-01,\n",
       "          6.9123e-01, -4.8070e-01,  2.9588e-01, -1.4164e+00,  4.7768e-02,\n",
       "         -3.0672e-01,  6.5002e-01,  8.0798e-01,  7.9505e-01,  1.0955e+00,\n",
       "          5.7172e-01, -4.7363e-01, -6.3251e-03, -8.2754e-02, -7.6262e-01,\n",
       "          1.3294e+00,  1.3172e+00, -2.4578e-01,  6.8873e-01,  6.7397e-01,\n",
       "         -2.6932e-01,  2.0948e-01, -5.6561e-03,  8.1934e-01,  1.8727e-01,\n",
       "          2.5317e-01,  2.3338e-01, -2.0254e-01,  9.4475e-01, -1.3768e-01,\n",
       "          3.7350e-01,  5.3883e-01, -1.5882e-01,  1.7989e+00,  5.1357e-01,\n",
       "          1.1989e+00,  1.1681e+00,  8.3845e-01,  1.1853e+00, -2.1495e-01,\n",
       "         -2.8841e-01,  1.4011e+00,  7.0589e-03,  7.5146e-01, -2.4448e-01,\n",
       "          2.1255e+00,  7.5507e-01,  4.3251e-01,  1.1274e+00,  1.1514e+00,\n",
       "          1.0948e+00, -2.2032e-01,  6.8154e-02, -1.7867e-01,  1.9586e-01,\n",
       "         -9.1464e-01, -6.5947e-01,  1.5644e+00,  1.5939e+00,  5.1076e-01,\n",
       "         -1.2979e+00,  4.4813e-02, -6.1882e-01, -2.5115e-01, -1.1517e+00,\n",
       "          9.7635e-01,  1.0398e-01,  2.3097e-01,  6.7482e-01, -1.9341e-01,\n",
       "          1.1457e-01,  9.5017e-01,  2.3591e+00,  3.3750e-02,  8.2065e-01,\n",
       "         -3.6031e-01,  4.2420e-01,  1.2559e+00,  6.1287e-01,  1.7820e+00,\n",
       "          4.7830e-01, -8.0702e-02,  7.0087e-01,  4.8786e-01, -8.4116e-01,\n",
       "          9.0759e-01, -2.5535e-01, -1.0664e+00, -9.7254e-02, -1.0295e-01,\n",
       "          7.1780e-01, -7.5778e-01,  1.5163e-01,  6.2426e-01, -7.4462e-01,\n",
       "          2.2601e+00,  7.3574e-01,  6.9155e-01,  1.8230e-01, -9.2201e-01,\n",
       "          2.0216e-01,  1.4535e+00,  1.8660e-01]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), hidden_states=None, attentions=None))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits_per_image', 'logits_per_text', 'text_embeds', 'image_embeds', 'text_model_output', 'vision_model_output'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPooling(last_hidden_state=tensor([[[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
       "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
       "         [ 1.0580, -0.9600,  1.0018,  ..., -0.5155, -0.1437, -1.9444],\n",
       "         ...,\n",
       "         [ 0.3059, -1.5037, -0.4022,  ..., -0.0224,  0.9105, -0.3916],\n",
       "         [ 1.0118, -0.6701,  1.7742,  ..., -0.1556, -0.0250, -1.5062],\n",
       "         [-0.5152,  0.1658,  0.8876,  ..., -0.0675, -0.4551, -1.7960]],\n",
       "\n",
       "        [[ 0.3393,  0.1165,  0.1020,  ...,  0.2468,  0.5906,  0.1013],\n",
       "         [ 1.9753, -0.5844,  0.3685,  ...,  1.1658,  0.8050, -0.9801],\n",
       "         [ 1.0580, -0.9600,  1.0018,  ..., -0.5155, -0.1437, -1.9444],\n",
       "         ...,\n",
       "         [ 0.3059, -1.5037, -0.4022,  ..., -0.0224,  0.9105, -0.3916],\n",
       "         [-0.1433, -0.5163,  1.7099,  ..., -0.0795,  0.3609, -1.2437],\n",
       "         [ 0.0426,  0.0189,  1.2740,  ..., -0.4217, -0.4393, -1.3016]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-0.5152,  0.1658,  0.8876,  ..., -0.0675, -0.4551, -1.7960],\n",
       "        [ 0.0426,  0.0189,  1.2740,  ..., -0.4217, -0.4393, -1.3016]],\n",
       "       grad_fn=<IndexBackward0>), hidden_states=None, attentions=None)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs['text_model_output']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
